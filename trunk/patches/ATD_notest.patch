diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp
--- llvm-project.upstream/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp	2023-12-18 11:20:49.111183767 -0500
+++ llvm-project/clang/lib/CodeGen/CGOpenMPRuntimeGPU.cpp	2023-12-18 12:24:58.273789312 -0500
@@ -765,14 +765,13 @@
 void CGOpenMPRuntimeGPU::emitKernelInit(const OMPExecutableDirective &D,
                                         CodeGenFunction &CGF,
                                         EntryFunctionState &EST, bool IsSPMD) {
-  int32_t MinThreadsVal = 1, MaxThreadsVal = -1, MinTeamsVal = 1,
-          MaxTeamsVal = -1;
-  computeMinAndMaxThreadsAndTeams(D, CGF, MinThreadsVal, MaxThreadsVal,
-                                  MinTeamsVal, MaxTeamsVal);
+  // Get NumTeams and ThreadLimit attributes.
+  llvm::OpenMPIRBuilder::TargetKernelDefaultBounds Bounds;
+  computeMinAndMaxThreadsAndTeams(D, CGF, Bounds.MinThreads, Bounds.MaxThreads,
+                                  Bounds.MinTeams, Bounds.MaxTeams);
 
   CGBuilderTy &Bld = CGF.Builder;
-  Bld.restoreIP(OMPBuilder.createTargetInit(
-      Bld, IsSPMD, MinThreadsVal, MaxThreadsVal, MinTeamsVal, MaxTeamsVal));
+  Bld.restoreIP(OMPBuilder.createTargetInit(Bld, IsSPMD, Bounds));
   if (!IsSPMD)
     emitGenericVarsProlog(CGF, EST.Loc);
 }
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/clang/lib/Driver/ToolChains/Clang.cpp llvm-project/clang/lib/Driver/ToolChains/Clang.cpp
--- llvm-project.upstream/clang/lib/Driver/ToolChains/Clang.cpp	2023-12-18 11:20:49.127183707 -0500
+++ llvm-project/clang/lib/Driver/ToolChains/Clang.cpp	2023-12-18 11:22:55.990704903 -0500
@@ -8412,7 +8412,9 @@
   assert(Input.isFilename() && "Invalid input.");
   CmdArgs.push_back(Input.getFilename());
 
-  const char *Exec = getToolChain().getDriver().getClangProgramPath();
+  // TODO This is a workaround to enable using -save-temps with flang-new
+  // const char *Exec = getToolChain().getDriver().getClangProgramPath();
+  const char *Exec = Args.MakeArgString(getToolChain().GetProgramPath("clang"));
   if (D.CC1Main && !D.CCGenDiagnostics) {
     // Invoke cc1as directly in this process.
     C.addCommand(std::make_unique<CC1Command>(
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/flang/lib/Lower/OpenMP.cpp llvm-project/flang/lib/Lower/OpenMP.cpp
--- llvm-project.upstream/flang/lib/Lower/OpenMP.cpp	2023-12-18 11:20:49.339182907 -0500
+++ llvm-project/flang/lib/Lower/OpenMP.cpp	2023-12-18 12:24:58.277789298 -0500
@@ -38,6 +38,19 @@
     llvm::cl::desc("In the OpenMP data clauses treat `a(N)` as `a(N:N)`."),
     llvm::cl::init(true));
 
+#include <algorithm>
+#include <functional>
+#include <iterator>
+#include <list>
+#include <numeric>
+#include <optional>
+#include <sstream>
+#include <string>
+#include <tuple>
+#include <type_traits>
+#include <utility>
+#include <variant>
+
 using DeclareTargetCapturePair =
     std::pair<mlir::omp::DeclareTargetCaptureClause,
               Fortran::semantics::Symbol>;
@@ -109,6 +122,18 @@
   }
 }
 
+static mlir::omp::TargetOp findParentTargetOp(mlir::OpBuilder &builder) {
+  mlir::Operation *parentOp = builder.getBlock()->getParentOp();
+  if (!parentOp)
+    return nullptr;
+
+  auto targetOp = llvm::dyn_cast<mlir::omp::TargetOp>(parentOp);
+  if (!targetOp)
+    targetOp = parentOp->getParentOfType<mlir::omp::TargetOp>();
+
+  return targetOp;
+}
+
 //===----------------------------------------------------------------------===//
 // DataSharingProcessor
 //===----------------------------------------------------------------------===//
@@ -1911,6 +1936,75 @@
 }
 
 //===----------------------------------------------------------------------===//
+// HostClausesInsertionGuard
+//===----------------------------------------------------------------------===//
+
+/// If the insertion point of the builder is located inside of an omp.target
+/// region, this RAII guard moves the insertion point to just before that
+/// omp.target operation and then restores the original insertion point when
+/// destroyed. If not currently inserting inside an omp.target, it remains
+/// unchanged.
+class HostClausesInsertionGuard {
+public:
+  HostClausesInsertionGuard(mlir::OpBuilder &builder) : builder(builder) {
+    targetOp = findParentTargetOp(builder);
+    if (targetOp) {
+      ip = builder.saveInsertionPoint();
+      builder.setInsertionPoint(targetOp);
+    }
+  }
+
+  ~HostClausesInsertionGuard() {
+    if (ip.isSet()) {
+      fixupExtractedHostOps();
+      builder.restoreInsertionPoint(ip);
+    }
+  }
+
+private:
+  mlir::OpBuilder &builder;
+  mlir::OpBuilder::InsertPoint ip;
+  mlir::omp::TargetOp targetOp;
+
+  /// Fixup any uses of target region block arguments that we have just created
+  /// outside of the target region, and replace them by their host values.
+  void fixupExtractedHostOps() {
+    auto useOutsideTargetRegion = [](mlir::OpOperand &operand) {
+      if (mlir::Operation *owner = operand.getOwner())
+        return !owner->getParentOfType<mlir::omp::TargetOp>();
+      return false;
+    };
+
+    mlir::OperandRange map = targetOp.getMapOperands();
+    for (mlir::BlockArgument arg : targetOp.getRegion().getArguments()) {
+      mlir::Value hostVal = map[arg.getArgNumber()]
+                                .getDefiningOp<mlir::omp::MapInfoOp>()
+                                .getVarPtr();
+
+      // Replace instances of omp.target block arguments used outside with their
+      // corresponding host value.
+      arg.replaceUsesWithIf(hostVal, [&](mlir::OpOperand &operand) -> bool {
+        // If the use is an hlfir.declare, we need to search for the matching
+        // one within host code.
+        if (auto declareOp = llvm::dyn_cast_if_present<hlfir::DeclareOp>(
+                operand.getOwner())) {
+          if (auto hostDeclareOp = hostVal.getDefiningOp<hlfir::DeclareOp>()) {
+            declareOp->replaceUsesWithIf(hostDeclareOp.getResults(),
+                                         useOutsideTargetRegion);
+          } else if (auto hostBoxOp = hostVal.getDefiningOp<fir::BoxAddrOp>()) {
+            declareOp->replaceUsesWithIf(hostBoxOp.getVal()
+                                             .getDefiningOp<hlfir::DeclareOp>()
+                                             .getResults(),
+                                         useOutsideTargetRegion);
+          }
+        }
+        return useOutsideTargetRegion(operand);
+      });
+    }
+  }
+};
+
+//===----------------------------------------------------------------------===//
 // Code generation helper functions
 //===----------------------------------------------------------------------===//
 
@@ -2090,6 +2184,83 @@
   return storeOp;
 }
 
+static mlir::Value
+calculateTripCount(Fortran::lower::AbstractConverter &converter,
+                   mlir::Location loc, llvm::ArrayRef<mlir::Value> lbs,
+                   llvm::ArrayRef<mlir::Value> ubs,
+                   llvm::ArrayRef<mlir::Value> steps) {
+  using namespace mlir::arith;
+  assert(lbs.size() == ubs.size() && lbs.size() == steps.size() &&
+         !lbs.empty() && "Invalid bounds or step");
+
+  fir::FirOpBuilder &b = converter.getFirOpBuilder();
+
+  // Get the bit width of an integer-like type.
+  auto widthOf = [](mlir::Type ty) -> unsigned {
+    if (mlir::isa<mlir::IndexType>(ty)) {
+      return mlir::IndexType::kInternalStorageBitWidth;
+    }
+    if (auto tyInt = mlir::dyn_cast<mlir::IntegerType>(ty)) {
+      return tyInt.getWidth();
+    }
+    llvm_unreachable("Unexpected type");
+  };
+
+  // For a type that is either IntegerType or IndexType, return the
+  // equivalent IntegerType. In the former case this is a no-op.
+  auto asIntTy = [&](mlir::Type ty) -> mlir::IntegerType {
+    if (ty.isIndex()) {
+      return mlir::IntegerType::get(ty.getContext(), widthOf(ty));
+    }
+    assert(ty.isIntOrIndex() && "Unexpected type");
+    return mlir::cast<mlir::IntegerType>(ty);
+  };
+
+  // For two given values, establish a common signless IntegerType
+  // that can represent any value of type of x and of type of y,
+  // and return the pair of x, y converted to the new type.
+  auto unifyToSignless =
+      [&](fir::FirOpBuilder &b, mlir::Value x,
+          mlir::Value y) -> std::pair<mlir::Value, mlir::Value> {
+    auto tyX = asIntTy(x.getType()), tyY = asIntTy(y.getType());
+    unsigned width = std::max(widthOf(tyX), widthOf(tyY));
+    auto wideTy = mlir::IntegerType::get(b.getContext(), width,
+                                         mlir::IntegerType::Signless);
+    return std::make_pair(b.createConvert(loc, wideTy, x),
+                          b.createConvert(loc, wideTy, y));
+  };
+
+  // Start with signless i32 by default.
+  auto tripCount = b.createIntegerConstant(loc, b.getI32Type(), 1);
+
+  for (auto [origLb, origUb, origStep] : llvm::zip(lbs, ubs, steps)) {
+    auto tmpS0 = b.createIntegerConstant(loc, origStep.getType(), 0);
+    auto [step, step0] = unifyToSignless(b, origStep, tmpS0);
+    auto reverseCond = b.create<CmpIOp>(loc, CmpIPredicate::slt, step, step0);
+    auto negStep = b.create<SubIOp>(loc, step0, step);
+    mlir::Value absStep = b.create<SelectOp>(loc, reverseCond, negStep, step);
+
+    auto [lb, ub] = unifyToSignless(b, origLb, origUb);
+    auto start = b.create<SelectOp>(loc, reverseCond, ub, lb);
+    auto end = b.create<SelectOp>(loc, reverseCond, lb, ub);
+
+    mlir::Value range = b.create<SubIOp>(loc, end, start);
+    auto rangeCond = b.create<CmpIOp>(loc, CmpIPredicate::slt, end, start);
+    std::tie(range, absStep) = unifyToSignless(b, range, absStep);
+    // numSteps = (range /u absStep) + 1
+    auto numSteps =
+        b.create<AddIOp>(loc, b.create<DivUIOp>(loc, range, absStep),
+                         b.createIntegerConstant(loc, range.getType(), 1));
+
+    auto trip0 = b.createIntegerConstant(loc, numSteps.getType(), 0);
+    auto loopTripCount = b.create<SelectOp>(loc, rangeCond, trip0, numSteps);
+    auto [totalTC, thisTC] = unifyToSignless(b, tripCount, loopTripCount);
+    tripCount = b.create<MulIOp>(loc, totalTC, thisTC);
+  }
+
+  return tripCount;
+}
+
 /// Create the body (block) for an OpenMP Operation.
 ///
 /// \param [in]    op - the operation the body belongs to.
@@ -2271,6 +2442,27 @@
       /*clauseList=*/nullptr, /*simd=*/false);
 }
 
+static bool evalHasSiblings(Fortran::lower::pft::Evaluation &eval) {
+  return eval.parent.visit(Fortran::common::visitors{
+      [&](const Fortran::lower::pft::Program &parent) {
+        return parent.getUnits().size() + parent.getCommonBlocks().size() > 1;
+      },
+      [&](const Fortran::lower::pft::Evaluation &parent) {
+        for (auto &sibling : *parent.evaluationList)
+          if (&sibling != &eval && !sibling.isEndStmt())
+            return true;
+
+        return false;
+      },
+      [&](const auto &parent) {
+        for (auto &sibling : parent.evaluationList)
+          if (&sibling != &eval && !sibling.isEndStmt())
+            return true;
+
+        return false;
+      }});
+}
+
 static mlir::omp::ParallelOp
 genParallelOp(Fortran::lower::AbstractConverter &converter,
               Fortran::lower::pft::Evaluation &eval,
@@ -2287,23 +2479,46 @@
   ClauseProcessor cp(converter, clauseList);
   cp.processIf(Fortran::parser::OmpIfClause::DirectiveNameModifier::Parallel,
                ifClauseOperand);
-  cp.processNumThreads(stmtCtx, numThreadsClauseOperand);
   cp.processProcBind(procBindKindAttr);
   cp.processDefault();
   cp.processAllocate(allocatorOperands, allocateOperands);
   if (!outerCombined)
     cp.processReduction(currentLocation, reductionVars, reductionDeclSymbols);
 
-  return genOpWithBody<mlir::omp::ParallelOp>(
+  auto offloadModOp =
+      llvm::cast<mlir::omp::OffloadModuleInterface>(*converter.getModuleOp());
+  mlir::omp::TargetOp targetOp =
+      findParentTargetOp(converter.getFirOpBuilder());
+
+  bool mustEvalOutsideTarget =
+      targetOp && !offloadModOp.getIsTargetDevice() && !evalHasSiblings(eval);
+  if (mustEvalOutsideTarget) {
+    HostClausesInsertionGuard guard(converter.getFirOpBuilder());
+    cp.processNumThreads(stmtCtx, numThreadsClauseOperand);
+  } else {
+    cp.processNumThreads(stmtCtx, numThreadsClauseOperand);
+  }
+
+  auto parallelOp = genOpWithBody<mlir::omp::ParallelOp>(
       converter, eval, currentLocation, outerCombined, &clauseList,
       /*resultTypes=*/mlir::TypeRange(), ifClauseOperand,
-      numThreadsClauseOperand, allocateOperands, allocatorOperands,
+      /*num_threads_var=*/nullptr, allocateOperands, allocatorOperands,
       reductionVars,
       reductionDeclSymbols.empty()
           ? nullptr
           : mlir::ArrayAttr::get(converter.getFirOpBuilder().getContext(),
                                  reductionDeclSymbols),
       procBindKindAttr);
+
+  if (mustEvalOutsideTarget) {
+    if (numThreadsClauseOperand)
+      targetOp.getNumThreadsMutable().assign(numThreadsClauseOperand);
+  } else {
+    if (numThreadsClauseOperand)
+      parallelOp.getNumThreadsVarMutable().assign(numThreadsClauseOperand);
+  }
+
+  return parallelOp;
 }
 
 static mlir::omp::SingleOp
@@ -2617,13 +2832,12 @@
   llvm::SmallVector<const Fortran::semantics::Symbol *> mapSymbols;
 
   ClauseProcessor cp(converter, clauseList);
-  cp.processIf(Fortran::parser::OmpIfClause::DirectiveNameModifier::Target,
-               ifClauseOperand);
   cp.processDevice(stmtCtx, deviceOperand);
-  cp.processThreadLimit(stmtCtx, threadLimitOperand);
-  cp.processNowait(nowaitAttr);
   cp.processMap(currentLocation, directive, semanticsContext, stmtCtx,
                 mapOperands, &mapSymTypes, &mapSymLocs, &mapSymbols);
+  cp.processIf(Fortran::parser::OmpIfClause::DirectiveNameModifier::Target,
+               ifClauseOperand);
+  cp.processThreadLimit(stmtCtx, threadLimitOperand);
   cp.processTODO<Fortran::parser::OmpClause::Private,
                  Fortran::parser::OmpClause::Depend,
                  Fortran::parser::OmpClause::Firstprivate,
@@ -2636,6 +2850,11 @@
                  Fortran::parser::OmpClause::Defaultmap>(
       currentLocation, llvm::omp::Directive::OMPD_target);
 
+  // Process host-only clauses.
+  if (!llvm::cast<mlir::omp::OffloadModuleInterface>(*converter.getModuleOp())
+           .getIsTargetDevice())
+    cp.processNowait(nowaitAttr);
+
   // 5.8.1 Implicit Data-Mapping Attribute Rules
   // The following code follows the implicit data-mapping rules to map all the
   // symbols used inside the region that have not been explicitly mapped using
@@ -2703,7 +2922,9 @@
 
   auto targetOp = converter.getFirOpBuilder().create<mlir::omp::TargetOp>(
       currentLocation, ifClauseOperand, deviceOperand, threadLimitOperand,
-      nowaitAttr, mapOperands);
+      /*trip_count=*/nullptr, nowaitAttr, mapOperands,
+      /*num_teams_lower=*/nullptr, /*num_teams_upper=*/nullptr,
+      /*teams_thread_limit=*/nullptr, /*num_threads=*/nullptr);
 
   genBodyOfTargetOp(converter, eval, targetOp, mapSymTypes, mapSymLocs,
                     mapSymbols, currentLocation);
@@ -2728,20 +2949,63 @@
                ifClauseOperand);
   cp.processAllocate(allocatorOperands, allocateOperands);
   cp.processDefault();
-  cp.processNumTeams(stmtCtx, numTeamsClauseOperand);
-  cp.processThreadLimit(stmtCtx, threadLimitClauseOperand);
   cp.processTODO<Fortran::parser::OmpClause::Reduction>(
       currentLocation, llvm::omp::Directive::OMPD_teams);
 
-  return genOpWithBody<mlir::omp::TeamsOp>(
+  // Evaluate NUM_TEAMS and THREAD_LIMIT on the host device, if currently inside
+  // of an omp.target operation.
+  auto offloadModOp = llvm::cast<mlir::omp::OffloadModuleInterface>(
+      converter.getModuleOp().getOperation());
+  mlir::omp::TargetOp targetOp =
+      findParentTargetOp(converter.getFirOpBuilder());
+
+  bool mustEvalOutsideTarget = targetOp && !offloadModOp.getIsTargetDevice();
+  if (mustEvalOutsideTarget) {
+    HostClausesInsertionGuard guard(converter.getFirOpBuilder());
+    cp.processNumTeams(stmtCtx, numTeamsClauseOperand);
+    cp.processThreadLimit(stmtCtx, threadLimitClauseOperand);
+  } else {
+    cp.processNumTeams(stmtCtx, numTeamsClauseOperand);
+    cp.processThreadLimit(stmtCtx, threadLimitClauseOperand);
+  }
+
+  auto teamsOp = genOpWithBody<mlir::omp::TeamsOp>(
       converter, eval, currentLocation, outerCombined, &clauseList,
-      /*num_teams_lower=*/nullptr, numTeamsClauseOperand, ifClauseOperand,
-      threadLimitClauseOperand, allocateOperands, allocatorOperands,
+      /*num_teams_lower=*/nullptr, /*num_teams_upper=*/nullptr, ifClauseOperand,
+      /*thread_limit=*/nullptr, allocateOperands, allocatorOperands,
       reductionVars,
       reductionDeclSymbols.empty()
           ? nullptr
           : mlir::ArrayAttr::get(converter.getFirOpBuilder().getContext(),
                                  reductionDeclSymbols));
+  if (mustEvalOutsideTarget) {
+    if (numTeamsClauseOperand)
+      targetOp.getNumTeamsUpperMutable().assign(numTeamsClauseOperand);
+    if (threadLimitClauseOperand)
+      targetOp.getTeamsThreadLimitMutable().assign(threadLimitClauseOperand);
+  } else {
+    if (numTeamsClauseOperand)
+      teamsOp.getNumTeamsUpperMutable().assign(numTeamsClauseOperand);
+    if (threadLimitClauseOperand)
+      teamsOp.getThreadLimitMutable().assign(threadLimitClauseOperand);
+  }
+
+  return teamsOp;
+}
+
+static mlir::omp::DistributeOp
+genDistributeOp(Fortran::lower::AbstractConverter &converter,
+                Fortran::lower::pft::Evaluation &eval,
+                mlir::Location currentLocation,
+                const Fortran::parser::OmpClauseList &clauseList,
+                bool outerCombined = false) {
+  // TODO Process clauses
+  // ClauseProcessor cp(converter, clauseList);
+  // cp.processAllocate(allocatorOperands, allocateOperands);
+  // ...
+
+  return genOpWithBody<mlir::omp::DistributeOp>(
+      converter, eval, currentLocation, outerCombined, &clauseList);
 }
 
 /// Extract the list of function and variable symbols affected by the given
@@ -2810,10 +3074,6 @@
   return std::nullopt;
 }
 
-//===----------------------------------------------------------------------===//
-// genOMP() Code generation helper functions
-//===----------------------------------------------------------------------===//
-
 static void
 genOmpSimpleStandalone(Fortran::lower::AbstractConverter &converter,
                        Fortran::lower::pft::Evaluation &eval,
@@ -2880,6 +3140,10 @@
       converter.getCurrentLocation(), operandRange);
 }
 
+//===----------------------------------------------------------------------===//
+// genOMP() Code generation helper functions
+//===----------------------------------------------------------------------===//
+
 static void
 genOMP(Fortran::lower::AbstractConverter &converter,
        Fortran::lower::pft::Evaluation &eval,
@@ -2953,7 +3217,9 @@
     }
     if (llvm::omp::allDistributeSet.test(ompDirective)) {
       validDirective = true;
-      TODO(currentLocation, "Distribute construct");
+      bool outerCombined = llvm::omp::topDistributeSet.test(ompDirective);
+      genDistributeOp(converter, eval, currentLocation, loopOpClauseList,
+                      outerCombined);
     }
     if ((llvm::omp::allParallelSet & llvm::omp::loopConstructSet)
             .test(ompDirective)) {
@@ -3062,6 +3328,26 @@
   createBodyOfOp<mlir::omp::WsLoopOp>(wsLoopOp, converter, currentLocation,
                                       eval, &loopOpClauseList, iv,
                                       /*outer=*/false, &dsp);
+
+  // Create trip_count if inside of omp.target and this is host compilation
+  auto offloadMod = llvm::dyn_cast<mlir::omp::OffloadModuleInterface>(
+      firOpBuilder.getModule().getOperation());
+  auto targetOp = wsLoopOp->getParentOfType<mlir::omp::TargetOp>();
+
+  if (offloadMod && targetOp && !offloadMod.getIsTargetDevice() &&
+      targetOp.isTargetSPMDLoop()) {
+    // Lower loop bounds and step, and process collapsing again, putting lowered
+    // values outside of omp.target this time. This enables calculating and
+    // accessing the trip count in the host, which is needed when lowering to
+    // LLVM IR via the OMPIRBuilder.
+    HostClausesInsertionGuard guard(firOpBuilder);
+    llvm::SmallVector<mlir::Value> outsideLB, outsideUB, outsideStep;
+    llvm::SmallVector<const Fortran::semantics::Symbol *> outsideIV;
+    cp.processCollapse(currentLocation, eval, outsideLB, outsideUB, outsideStep,
+                       outsideIV, loopVarTypeSize);
+    targetOp.getTripCountMutable().assign(calculateTripCount(
+        converter, currentLocation, outsideLB, outsideUB, outsideStep));
+  }
 }
 
 static void
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/llvm/include/llvm/Frontend/OpenMP/OMPIRBuilder.h llvm-project/llvm/include/llvm/Frontend/OpenMP/OMPIRBuilder.h
--- llvm-project.upstream/llvm/include/llvm/Frontend/OpenMP/OMPIRBuilder.h	2023-12-18 11:20:49.639181774 -0500
+++ llvm-project/llvm/include/llvm/Frontend/OpenMP/OMPIRBuilder.h	2023-12-18 12:24:58.277789298 -0500
@@ -90,9 +90,14 @@
   /// Flag for specifying if the compilation is done for an accelerator.
   std::optional<bool> IsGPU;
 
-  // Flag for specifying if offloading is mandatory.
+  /// Flag for specifying if offloading is mandatory.
   std::optional<bool> OpenMPOffloadMandatory;
 
+  /// Name of the target processor.
+  StringRef TargetCPU;
+  /// String representation of the target processor's features.
+  StringRef TargetFeatures;
+
   /// First separator used between the initial two parts of a name.
   std::optional<StringRef> FirstSeparator;
   /// Separator used between all of the rest consecutive parts of s name
@@ -1598,6 +1603,29 @@
           MapNamesArray(MapNamesArray) {}
   };
 
+  /// Container to pass the default bounds for the number of teams and threads
+  /// with which a kernel must be launched, used to set kernel attributes and
+  /// populate associated static structures.
+  struct TargetKernelDefaultBounds {
+    int32_t MinTeams = 1;
+    int32_t MaxTeams = -1;
+    int32_t MinThreads = 1;
+    int32_t MaxThreads = -1;
+  };
+
+  /// Container to pass the runtime SSA values or constants related to the
+  /// number of teams and threads with which the kernel must be launched, as
+  /// well as the trip count of the loop. These must be defined in the host code
+  /// prior to the call to the kernel launch OpenMP RTL function.
+  struct TargetKernelRuntimeBounds {
+    Value *LoopTripCount = nullptr;
+    Value *TargetThreadLimit = nullptr;
+    Value *TeamsThreadLimit = nullptr;
+    Value *MinTeams = nullptr;
+    Value *MaxTeams = nullptr;
+    Value *MaxThreads = nullptr;
+  };
+
   /// Data structure that contains the needed information to construct the
   /// kernel args vector.
   struct TargetKernelArgs {
@@ -1606,7 +1634,7 @@
     /// Arguments passed to the runtime library
     TargetDataRTArgs RTArgs;
     /// The number of iterations
-    Value *NumIterations;
+    Value *TripCount;
     /// The number of teams.
     Value *NumTeams;
     /// The number of threads.
@@ -1618,12 +1646,11 @@
 
     /// Constructor for TargetKernelArgs
     TargetKernelArgs(unsigned NumTargetItems, TargetDataRTArgs RTArgs,
-                     Value *NumIterations, Value *NumTeams, Value *NumThreads,
+                     Value *TripCount, Value *NumTeams, Value *NumThreads,
                      Value *DynCGGroupMem, bool HasNoWait)
-        : NumTargetItems(NumTargetItems), RTArgs(RTArgs),
-          NumIterations(NumIterations), NumTeams(NumTeams),
-          NumThreads(NumThreads), DynCGGroupMem(DynCGGroupMem),
-          HasNoWait(HasNoWait) {}
+        : NumTargetItems(NumTargetItems), RTArgs(RTArgs), TripCount(TripCount),
+          NumTeams(NumTeams), NumThreads(NumThreads),
+          DynCGGroupMem(DynCGGroupMem), HasNoWait(HasNoWait) {}
   };
 
   /// Create the kernel args vector used by emitTargetKernel. This function
@@ -1936,6 +1963,14 @@
               Value *NumTeamsLower = nullptr, Value *NumTeamsUpper = nullptr,
               Value *ThreadLimit = nullptr, Value *IfExpr = nullptr);
 
+  /// Generator for `#omp distribute`
+  ///
+  /// \param Loc The location where the teams construct was encountered.
+  /// \param AllocaIP The insertion points to be used for alloca instructions.
+  /// \param BodyGenCB Callback that will generate the region code.
+  InsertPointTy createDistribute(const LocationDescription &Loc,
+                                 InsertPointTy AllocaIP,
+                                 BodyGenCallbackTy BodyGenCB);
   /// Generate conditional branch and relevant BasicBlocks through which private
   /// threads copy the 'copyin' variables from Master copy to threadprivate
   /// copies.
@@ -2048,15 +2083,10 @@
   ///
   /// \param Loc The insert and source location description.
   /// \param IsSPMD Flag to indicate if the kernel is an SPMD kernel or not.
-  /// \param MinThreads Minimal number of threads, or 0.
-  /// \param MaxThreads Maximal number of threads, or 0.
-  /// \param MinTeams Minimal number of teams, or 0.
-  /// \param MaxTeams Maximal number of teams, or 0.
-  InsertPointTy createTargetInit(const LocationDescription &Loc, bool IsSPMD,
-                                 int32_t MinThreadsVal = 0,
-                                 int32_t MaxThreadsVal = 0,
-                                 int32_t MinTeamsVal = 0,
-                                 int32_t MaxTeamsVal = 0);
+  /// \param Bounds The default kernel lanuch bounds.
+  InsertPointTy createTargetInit(
+      const LocationDescription &Loc, bool IsSPMD,
+      const llvm::OpenMPIRBuilder::TargetKernelDefaultBounds &Bounds);
 
   /// Create a runtime call for kmpc_target_deinit
   ///
@@ -2082,6 +2112,9 @@
   static void writeThreadBoundsForKernel(const Triple &T, Function &Kernel,
                                          int32_t LB, int32_t UB);
 
+  /// Write the global variable to indicate which amdgcn ABI to use
+  static void emit__oclc_ABI_version(Module &M, int32_t COV);
+
   /// Read/write a bounds on teams for \p Kernel. Read will return 0 if none
   /// is set.
   static std::pair<int32_t, int32_t> readTeamBoundsForKernel(const Triple &T,
@@ -2156,7 +2189,6 @@
                                          Function *OutlinedFunction,
                                          StringRef EntryFnName,
                                          StringRef EntryFnIDName);
-
   /// Type of BodyGen to use for region codegen
   ///
   /// Priv: If device pointer privatization is required, emit the body of the
@@ -2215,21 +2247,23 @@
   /// Generator for '#omp target'
   ///
   /// \param Loc where the target data construct was encountered.
+  /// \param IsSPMD whether this is an SPMD target launch.
   /// \param CodeGenIP The insertion point where the call to the outlined
   /// function should be emitted.
   /// \param EntryInfo The entry information about the function.
-  /// \param NumTeams Number of teams specified in the num_teams clause.
-  /// \param NumThreads Number of teams specified in the thread_limit clause.
+  /// \param DefaultBounds The default kernel lanuch bounds.
+  /// \param RuntimeBounds The runtime kernel lanuch bounds.
   /// \param Inputs The input values to the region that will be passed.
   /// as arguments to the outlined function.
   /// \param BodyGenCB Callback that will generate the region code.
   /// \param ArgAccessorFuncCB Callback that will generate accessors
   /// instructions for passed in target arguments where neccessary
-  InsertPointTy createTarget(const LocationDescription &Loc,
+  InsertPointTy createTarget(const LocationDescription &Loc, bool IsSPMD,
                              OpenMPIRBuilder::InsertPointTy AllocaIP,
                              OpenMPIRBuilder::InsertPointTy CodeGenIP,
-                             TargetRegionEntryInfo &EntryInfo, int32_t NumTeams,
-                             int32_t NumThreads,
+                             TargetRegionEntryInfo &EntryInfo,
+                             const TargetKernelDefaultBounds &DefaultBounds,
+                             const TargetKernelRuntimeBounds &RuntimeBounds,
                              SmallVectorImpl<Value *> &Inputs,
                              GenMapInfoCallbackTy GenMapInfoCB,
                              TargetBodyGenCallbackTy BodyGenCB,
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp
--- llvm-project.upstream/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp	2023-12-18 11:20:49.731181427 -0500
+++ llvm-project/llvm/lib/Frontend/OpenMP/OMPIRBuilder.cpp	2023-12-18 12:24:58.281789284 -0500
@@ -510,7 +510,7 @@
                 KernelArgs.RTArgs.MapTypesArray,
                 KernelArgs.RTArgs.MapNamesArray,
                 KernelArgs.RTArgs.MappersArray,
-                KernelArgs.NumIterations,
+                KernelArgs.TripCount,
                 Flags,
                 NumTeams3D,
                 NumThreads3D,
@@ -1132,7 +1132,6 @@
   CallInst *CI = cast<CallInst>(OutlinedFn.user_back());
   assert(CI && "Expected call instruction to outlined function");
   CI->getParent()->setName("omp_parallel");
-
   Builder.SetInsertPoint(CI);
   Type *PtrTy = OMPIRBuilder->VoidPtr;
   Value *NullPtrValue = Constant::getNullValue(PtrTy);
@@ -4441,10 +4440,9 @@
   return Builder.CreateCall(Fn, Args);
 }
 
-OpenMPIRBuilder::InsertPointTy
-OpenMPIRBuilder::createTargetInit(const LocationDescription &Loc, bool IsSPMD,
-                                  int32_t MinThreadsVal, int32_t MaxThreadsVal,
-                                  int32_t MinTeamsVal, int32_t MaxTeamsVal) {
+OpenMPIRBuilder::InsertPointTy OpenMPIRBuilder::createTargetInit(
+    const LocationDescription &Loc, bool IsSPMD,
+    const llvm::OpenMPIRBuilder::TargetKernelDefaultBounds &Bounds) {
   if (!updateToLocation(Loc))
     return Loc.IP;
 
@@ -4461,21 +4459,23 @@
 
   // Manifest the launch configuration in the metadata matching the kernel
   // environment.
-  if (MinTeamsVal > 1 || MaxTeamsVal > 0)
-    writeTeamsForKernel(T, *Kernel, MinTeamsVal, MaxTeamsVal);
+  if (Bounds.MinTeams > 1 || Bounds.MaxTeams > 0)
+    writeTeamsForKernel(T, *Kernel, Bounds.MinTeams, Bounds.MaxTeams);
 
-  // For max values, < 0 means unset, == 0 means set but unknown.
-  if (MaxThreadsVal < 0)
-    MaxThreadsVal = std::max(
-        int32_t(getGridValue(T, Kernel).GV_Default_WG_Size), MinThreadsVal);
-
-  if (MaxThreadsVal > 0)
-    writeThreadBoundsForKernel(T, *Kernel, MinThreadsVal, MaxThreadsVal);
-
-  Constant *MinThreads = ConstantInt::getSigned(Int32, MinThreadsVal);
-  Constant *MaxThreads = ConstantInt::getSigned(Int32, MaxThreadsVal);
-  Constant *MinTeams = ConstantInt::getSigned(Int32, MinTeamsVal);
-  Constant *MaxTeams = ConstantInt::getSigned(Int32, MaxTeamsVal);
+  // If MaxThreads not set, select the maximum between the default workgroup
+  // size and the MinThreads value.
+  int32_t MaxThreadsValue = Bounds.MaxThreads;
+  if (MaxThreadsValue < 0)
+    MaxThreadsValue = std::max(
+        int32_t(getGridValue(T, Kernel).GV_Default_WG_Size), Bounds.MinThreads);
+
+  if (MaxThreadsValue > 0)
+    writeThreadBoundsForKernel(T, *Kernel, Bounds.MinThreads, MaxThreadsValue);
+
+  Constant *MinThreads = ConstantInt::getSigned(Int32, Bounds.MinThreads);
+  Constant *MaxThreads = ConstantInt::getSigned(Int32, MaxThreadsValue);
+  Constant *MinTeams = ConstantInt::getSigned(Int32, Bounds.MinTeams);
+  Constant *MaxTeams = ConstantInt::getSigned(Int32, Bounds.MaxTeams);
   Constant *ReductionDataSize = ConstantInt::getSigned(Int32, 0);
   Constant *ReductionBufferLength = ConstantInt::getSigned(Int32, 0);
 
@@ -4712,6 +4712,11 @@
     if (T.isAMDGCN())
       OutlinedFn->setCallingConv(CallingConv::AMDGPU_KERNEL);
   }
+
+  if (!Config.TargetCPU.empty())
+    OutlinedFn->addFnAttr("target-cpu", Config.TargetCPU);
+  if (!Config.TargetFeatures.empty())
+    OutlinedFn->addFnAttr("target-features", Config.TargetFeatures);
 }
 
 Constant *OpenMPIRBuilder::createOutlinedFunctionID(Function *OutlinedFn,
@@ -4976,6 +4981,45 @@
   return getOrCreateRuntimeFunction(M, Name);
 }
 
+static void emitUsed(StringRef Name, std::vector<llvm::WeakTrackingVH> &List,
+                     Type *Int8PtrTy, Module &M) {
+  if (List.empty())
+    return;
+
+  // Convert List to what ConstantArray needs.
+  SmallVector<Constant *, 8> UsedArray;
+  UsedArray.resize(List.size());
+  for (unsigned i = 0, e = List.size(); i != e; ++i) {
+    UsedArray[i] = ConstantExpr::getPointerBitCastOrAddrSpaceCast(
+        cast<Constant>(&*List[i]), Int8PtrTy);
+  }
+
+  if (UsedArray.empty())
+    return;
+  ArrayType *ATy = ArrayType::get(Int8PtrTy, UsedArray.size());
+
+  auto *GV =
+      new GlobalVariable(M, ATy, false, llvm::GlobalValue::AppendingLinkage,
+                         llvm::ConstantArray::get(ATy, UsedArray), Name);
+
+  GV->setSection("llvm.metadata");
+}
+
+static void
+emitExecutionMode(OpenMPIRBuilder &OMPBuilder, IRBuilderBase &Builder,
+                  StringRef FunctionName, bool Mode,
+                  std::vector<llvm::WeakTrackingVH> &LLVMCompilerUsed) {
+  auto Int8Ty = Type::getInt8Ty(Builder.getContext());
+  auto *GVMode = new llvm::GlobalVariable(
+      OMPBuilder.M, Int8Ty, /*isConstant=*/true,
+      llvm::GlobalValue::WeakAnyLinkage,
+      llvm::ConstantInt::get(Int8Ty, Mode ? OMP_TGT_EXEC_MODE_SPMD
+                                          : OMP_TGT_EXEC_MODE_GENERIC),
+      Twine(FunctionName, "_exec_mode"));
+  GVMode->setVisibility(llvm::GlobalVariable::ProtectedVisibility);
+  LLVMCompilerUsed.emplace_back(GVMode);
+}
+
 static void replaceConstatExprUsesInFuncWithInstr(ConstantExpr *ConstExpr,
                                                   Function *Func) {
   for (User *User : make_early_inc_range(ConstExpr->users()))
@@ -4993,8 +5037,9 @@
 }
 
 static Function *createOutlinedFunction(
-    OpenMPIRBuilder &OMPBuilder, IRBuilderBase &Builder, StringRef FuncName,
-    SmallVectorImpl<Value *> &Inputs,
+    OpenMPIRBuilder &OMPBuilder, IRBuilderBase &Builder, bool IsSPMD,
+    const OpenMPIRBuilder::TargetKernelDefaultBounds &DefaultBounds,
+    StringRef FuncName, SmallVectorImpl<Value *> &Inputs,
     OpenMPIRBuilder::TargetBodyGenCallbackTy &CBFunc,
     OpenMPIRBuilder::TargetGenArgAccessorsCallbackTy &ArgAccessorFuncCB) {
   SmallVector<Type *> ParameterTypes;
@@ -5020,6 +5065,12 @@
   auto Func = Function::Create(FuncType, GlobalValue::InternalLinkage, FuncName,
                                Builder.GetInsertBlock()->getModule());
 
+  if (OMPBuilder.Config.isTargetDevice()) {
+    std::vector<llvm::WeakTrackingVH> LLVMCompilerUsed;
+    emitExecutionMode(OMPBuilder, Builder, FuncName, false, LLVMCompilerUsed);
+    Type *Int8PtrTy = Type::getInt8Ty(Builder.getContext())->getPointerTo();
+    emitUsed("llvm.compiler.used", LLVMCompilerUsed, Int8PtrTy, OMPBuilder.M);
+  }
   // Save insert point.
   auto OldInsertPoint = Builder.saveIP();
 
@@ -5029,7 +5080,8 @@
 
   // Insert target init call in the device compilation pass.
   if (OMPBuilder.Config.isTargetDevice())
-    Builder.restoreIP(OMPBuilder.createTargetInit(Builder, /*IsSPMD*/ false));
+    Builder.restoreIP(
+        OMPBuilder.createTargetInit(Builder, IsSPMD, DefaultBounds));
 
   BasicBlock *UserCodeEntryBB = Builder.GetInsertBlock();
 
@@ -5090,16 +5142,18 @@
 }
 
 static void emitTargetOutlinedFunction(
-    OpenMPIRBuilder &OMPBuilder, IRBuilderBase &Builder,
-    TargetRegionEntryInfo &EntryInfo, Function *&OutlinedFn,
-    Constant *&OutlinedFnID, SmallVectorImpl<Value *> &Inputs,
+    OpenMPIRBuilder &OMPBuilder, IRBuilderBase &Builder, bool IsSPMD,
+    TargetRegionEntryInfo &EntryInfo,
+    const OpenMPIRBuilder::TargetKernelDefaultBounds &DefaultBounds,
+    Function *&OutlinedFn, Constant *&OutlinedFnID,
+    SmallVectorImpl<Value *> &Inputs,
     OpenMPIRBuilder::TargetBodyGenCallbackTy &CBFunc,
     OpenMPIRBuilder::TargetGenArgAccessorsCallbackTy &ArgAccessorFuncCB) {
 
   OpenMPIRBuilder::FunctionGenCallback &&GenerateOutlinedFunction =
-      [&OMPBuilder, &Builder, &Inputs, &CBFunc,
-       &ArgAccessorFuncCB](StringRef EntryFnName) {
-        return createOutlinedFunction(OMPBuilder, Builder, EntryFnName, Inputs,
+      [&](StringRef EntryFnName) {
+        return createOutlinedFunction(OMPBuilder, Builder, IsSPMD,
+                                      DefaultBounds, EntryFnName, Inputs,
                                       CBFunc, ArgAccessorFuncCB);
       };
 
@@ -5107,12 +5161,14 @@
                                       OutlinedFn, OutlinedFnID);
 }
 
-static void emitTargetCall(OpenMPIRBuilder &OMPBuilder, IRBuilderBase &Builder,
-                           OpenMPIRBuilder::InsertPointTy AllocaIP,
-                           Function *OutlinedFn, Constant *OutlinedFnID,
-                           int32_t NumTeams, int32_t NumThreads,
-                           SmallVectorImpl<Value *> &Args,
-                           OpenMPIRBuilder::GenMapInfoCallbackTy GenMapInfoCB) {
+static void
+emitTargetCall(OpenMPIRBuilder &OMPBuilder, IRBuilderBase &Builder,
+               OpenMPIRBuilder::InsertPointTy AllocaIP,
+               const OpenMPIRBuilder::TargetKernelDefaultBounds &DefaultBounds,
+               const OpenMPIRBuilder::TargetKernelRuntimeBounds &RuntimeBounds,
+               Function *OutlinedFn, Constant *OutlinedFnID,
+               SmallVectorImpl<Value *> &Args,
+               OpenMPIRBuilder::GenMapInfoCallbackTy GenMapInfoCB) {
 
   OpenMPIRBuilder::TargetDataInfo Info(
       /*RequiresDevicePointerInfo=*/false,
@@ -5137,22 +5193,56 @@
   unsigned NumTargetItems = MapInfo.BasePointers.size();
   // TODO: Use correct device ID
   Value *DeviceID = Builder.getInt64(OMP_DEVICEID_UNDEF);
-  Value *NumTeamsVal = Builder.getInt32(NumTeams);
-  Value *NumThreadsVal = Builder.getInt32(NumThreads);
   uint32_t SrcLocStrSize;
   Constant *SrcLocStr = OMPBuilder.getOrCreateDefaultSrcLocStr(SrcLocStrSize);
   Value *RTLoc = OMPBuilder.getOrCreateIdent(SrcLocStr, SrcLocStrSize,
                                              llvm::omp::IdentFlag(0), 0);
-  // TODO: Use correct NumIterations
-  Value *NumIterations = Builder.getInt64(0);
+
+  Value *TripCount = RuntimeBounds.LoopTripCount
+                         ? Builder.CreateIntCast(RuntimeBounds.LoopTripCount,
+                                                 Builder.getInt64Ty(),
+                                                 /*isSigned=*/false)
+                         : Builder.getInt64(0);
+
+  Value *NumTeams = RuntimeBounds.MaxTeams
+                        ? RuntimeBounds.MaxTeams
+                        : Builder.getInt32(DefaultBounds.MaxTeams);
+
+  // Calculate number of threads: 0 if no clauses specified, otherwise it is the
+  // minimum between optional THREAD_LIMIT and MAX_THREADS clauses. Perform a
+  // type cast to uint32.
+  auto InitMaxThreadsClause = [&Builder](Value *Clause) {
+    if (Clause)
+      Clause = Builder.CreateIntCast(Clause, Builder.getInt32Ty(),
+                                     /*isSigned=*/false);
+    return Clause;
+  };
+
+  auto CombineMaxThreadsClauses = [&Builder](Value *Clause, Value *&Result) {
+    if (Clause)
+      Result = Result
+                   ? Builder.CreateSelect(Builder.CreateICmpULT(Result, Clause),
+                                          Result, Clause)
+                   : Clause;
+  };
+
+  Value *MaxThreadsClause = InitMaxThreadsClause(RuntimeBounds.MaxThreads);
+  Value *TeamsThreadLimitClause =
+      InitMaxThreadsClause(RuntimeBounds.TeamsThreadLimit);
+  Value *NumThreads = InitMaxThreadsClause(RuntimeBounds.TargetThreadLimit);
+  CombineMaxThreadsClauses(TeamsThreadLimitClause, NumThreads);
+  CombineMaxThreadsClauses(MaxThreadsClause, NumThreads);
+
+  if (!NumThreads)
+    NumThreads = Builder.getInt32(0);
+
   // TODO: Use correct DynCGGroupMem
   Value *DynCGGroupMem = Builder.getInt32(0);
-
   bool HasNoWait = false;
 
-  OpenMPIRBuilder::TargetKernelArgs KArgs(NumTargetItems, RTArgs, NumIterations,
-                                          NumTeamsVal, NumThreadsVal,
-                                          DynCGGroupMem, HasNoWait);
+  OpenMPIRBuilder::TargetKernelArgs KArgs(NumTargetItems, RTArgs, TripCount,
+                                          NumTeams, NumThreads, DynCGGroupMem,
+                                          HasNoWait);
 
   Builder.restoreIP(OMPBuilder.emitKernelLaunch(
       Builder, OutlinedFn, OutlinedFnID, EmitTargetCallFallbackCB, KArgs,
@@ -5160,10 +5250,11 @@
 }
 
 OpenMPIRBuilder::InsertPointTy OpenMPIRBuilder::createTarget(
-    const LocationDescription &Loc, InsertPointTy AllocaIP,
-    InsertPointTy CodeGenIP, TargetRegionEntryInfo &EntryInfo, int32_t NumTeams,
-    int32_t NumThreads, SmallVectorImpl<Value *> &Args,
-    GenMapInfoCallbackTy GenMapInfoCB,
+    const LocationDescription &Loc, bool IsSPMD, InsertPointTy AllocaIP,
+    InsertPointTy CodeGenIP, TargetRegionEntryInfo &EntryInfo,
+    const TargetKernelDefaultBounds &DefaultBounds,
+    const TargetKernelRuntimeBounds &RuntimeBounds,
+    SmallVectorImpl<Value *> &Args, GenMapInfoCallbackTy GenMapInfoCB,
     OpenMPIRBuilder::TargetBodyGenCallbackTy CBFunc,
     OpenMPIRBuilder::TargetGenArgAccessorsCallbackTy ArgAccessorFuncCB) {
   if (!updateToLocation(Loc))
@@ -5173,11 +5264,12 @@
 
   Function *OutlinedFn;
   Constant *OutlinedFnID;
-  emitTargetOutlinedFunction(*this, Builder, EntryInfo, OutlinedFn,
-                             OutlinedFnID, Args, CBFunc, ArgAccessorFuncCB);
+  emitTargetOutlinedFunction(*this, Builder, IsSPMD, EntryInfo, DefaultBounds,
+                             OutlinedFn, OutlinedFnID, Args, CBFunc,
+                             ArgAccessorFuncCB);
   if (!Config.isTargetDevice())
-    emitTargetCall(*this, Builder, AllocaIP, OutlinedFn, OutlinedFnID, NumTeams,
-                   NumThreads, Args, GenMapInfoCB);
+    emitTargetCall(*this, Builder, AllocaIP, DefaultBounds, RuntimeBounds,
+                   OutlinedFn, OutlinedFnID, Args, GenMapInfoCB);
 
   return Builder.saveIP();
 }
@@ -6199,6 +6291,43 @@
 }
 
 OpenMPIRBuilder::InsertPointTy
+OpenMPIRBuilder::createDistribute(const LocationDescription &Loc,
+                                  InsertPointTy OuterAllocaIP,
+                                  BodyGenCallbackTy BodyGenCB) {
+  if (!updateToLocation(Loc))
+    return InsertPointTy();
+
+  BasicBlock *OuterAllocaBB = OuterAllocaIP.getBlock();
+
+  if (OuterAllocaBB == Builder.GetInsertBlock()) {
+    BasicBlock *BodyBB =
+        splitBB(Builder, /*CreateBranch=*/true, "distribute.entry");
+    Builder.SetInsertPoint(BodyBB, BodyBB->begin());
+  }
+  BasicBlock *ExitBB =
+      splitBB(Builder, /*CreateBranch=*/true, "distribute.exit");
+  BasicBlock *BodyBB =
+      splitBB(Builder, /*CreateBranch=*/true, "distribute.body");
+  BasicBlock *AllocaBB =
+      splitBB(Builder, /*CreateBranch=*/true, "distribute.alloca");
+
+  // Generate the body of distribute clause
+  InsertPointTy AllocaIP(AllocaBB, AllocaBB->begin());
+  InsertPointTy CodeGenIP(BodyBB, BodyBB->begin());
+  BodyGenCB(AllocaIP, CodeGenIP);
+
+  OutlineInfo OI;
+  OI.OuterAllocaBB = OuterAllocaIP.getBlock();
+  OI.EntryBB = AllocaBB;
+  OI.ExitBB = ExitBB;
+
+  addOutlineInfo(std::move(OI));
+  Builder.SetInsertPoint(ExitBB, ExitBB->begin());
+
+  return Builder.saveIP();
+}
+
+OpenMPIRBuilder::InsertPointTy
 OpenMPIRBuilder::createTeams(const LocationDescription &Loc,
                              BodyGenCallbackTy BodyGenCB, Value *NumTeamsLower,
                              Value *NumTeamsUpper, Value *ThreadLimit,
@@ -6240,8 +6369,9 @@
   BasicBlock *AllocaBB =
       splitBB(Builder, /*CreateBranch=*/true, "teams.alloca");
 
-  // Push num_teams
-  if (NumTeamsLower || NumTeamsUpper || ThreadLimit || IfExpr) {
+  // Push num_teams if generating host fallback function
+  if (!Config.isTargetDevice() &&
+      (NumTeamsLower || NumTeamsUpper || ThreadLimit || IfExpr)) {
     assert((NumTeamsLower == nullptr || NumTeamsUpper != nullptr) &&
            "if lowerbound is non-null, then upperbound must also be non-null "
            "for bounds on num_teams");
@@ -6294,41 +6424,45 @@
   OI.ExcludeArgsFromAggregate.push_back(createFakeIntVal(
       Builder, OuterAllocaIP, ToBeDeleted, AllocaIP, "tid", true));
 
-  OI.PostOutlineCB = [this, Ident, ToBeDeleted](Function &OutlinedFn) mutable {
-    // The stale call instruction will be replaced with a new call instruction
-    // for runtime call with the outlined function.
-
-    assert(OutlinedFn.getNumUses() == 1 &&
-           "there must be a single user for the outlined function");
-    CallInst *StaleCI = cast<CallInst>(OutlinedFn.user_back());
-    ToBeDeleted.push(StaleCI);
-
-    assert((OutlinedFn.arg_size() == 2 || OutlinedFn.arg_size() == 3) &&
-           "Outlined function must have two or three arguments only");
-
-    bool HasShared = OutlinedFn.arg_size() == 3;
-
-    OutlinedFn.getArg(0)->setName("global.tid.ptr");
-    OutlinedFn.getArg(1)->setName("bound.tid.ptr");
-    if (HasShared)
-      OutlinedFn.getArg(2)->setName("data");
-
-    // Call to the runtime function for teams in the current function.
-    assert(StaleCI && "Error while outlining - no CallInst user found for the "
-                      "outlined function.");
-    Builder.SetInsertPoint(StaleCI);
-    SmallVector<Value *> Args = {
-        Ident, Builder.getInt32(StaleCI->arg_size() - 2), &OutlinedFn};
-    if (HasShared)
-      Args.push_back(StaleCI->getArgOperand(2));
-    Builder.CreateCall(getOrCreateRuntimeFunctionPtr(
-                           omp::RuntimeFunction::OMPRTL___kmpc_fork_teams),
-                       Args);
+  // Prevent unresolved __kmpc_fork_teams when device linking
+  if (!Config.isTargetDevice()) {
+    OI.PostOutlineCB = [this, Ident,
+                        ToBeDeleted](Function &OutlinedFn) mutable {
+      // The stale call instruction will be replaced with a new call instruction
+      // for runtime call with the outlined function.
+
+      assert(OutlinedFn.getNumUses() == 1 &&
+             "there must be a single user for the outlined function");
+      CallInst *StaleCI = cast<CallInst>(OutlinedFn.user_back());
+      ToBeDeleted.push(StaleCI);
+
+      assert((OutlinedFn.arg_size() == 2 || OutlinedFn.arg_size() == 3) &&
+             "Outlined function must have two or three arguments only");
+
+      bool HasShared = OutlinedFn.arg_size() == 3;
+
+      OutlinedFn.getArg(0)->setName("global.tid.ptr");
+      OutlinedFn.getArg(1)->setName("bound.tid.ptr");
+      if (HasShared)
+        OutlinedFn.getArg(2)->setName("data");
+
+      // Call to the runtime function for teams in the current function.
+      assert(StaleCI && "Error while outlining - no CallInst user found for "
+                        "the outlined function.");
+      Builder.SetInsertPoint(StaleCI);
+      SmallVector<Value *> Args = {
+          Ident, Builder.getInt32(StaleCI->arg_size() - 2), &OutlinedFn};
+      if (HasShared)
+        Args.push_back(StaleCI->getArgOperand(2));
+      Builder.CreateCall(getOrCreateRuntimeFunctionPtr(
+                             omp::RuntimeFunction::OMPRTL___kmpc_fork_teams),
+                         Args);
 
-    while (!ToBeDeleted.empty()) {
-      ToBeDeleted.top()->eraseFromParent();
-      ToBeDeleted.pop();
-    }
+      while (!ToBeDeleted.empty()) {
+        ToBeDeleted.top()->eraseFromParent();
+        ToBeDeleted.pop();
+      }
+    };
   };
 
   addOutlineInfo(std::move(OI));
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/llvm/lib/Transforms/IPO/OpenMPOpt.cpp llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp
--- llvm-project.upstream/llvm/lib/Transforms/IPO/OpenMPOpt.cpp	2023-12-18 11:20:49.927180687 -0500
+++ llvm-project/llvm/lib/Transforms/IPO/OpenMPOpt.cpp	2023-12-18 11:22:55.954705039 -0500
@@ -535,6 +535,7 @@
   void recollectUses() {
     for (int Idx = 0; Idx < RFIs.size(); ++Idx)
       recollectUsesForFunction(static_cast<RuntimeFunction>(Idx));
+    OMPBuilder.Config.IsTargetDevice = isOpenMPDevice(OMPBuilder.M);
   }
 
   // Helper function to inherit the calling convention of the function callee.
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/mlir/include/mlir/Dialect/OpenMP/OpenMPOps.td llvm-project/mlir/include/mlir/Dialect/OpenMP/OpenMPOps.td
--- llvm-project.upstream/mlir/include/mlir/Dialect/OpenMP/OpenMPOps.td	2023-12-18 11:20:50.535178392 -0500
+++ llvm-project/mlir/include/mlir/Dialect/OpenMP/OpenMPOps.td	2023-12-18 12:24:58.281789284 -0500
@@ -638,6 +638,26 @@
 }
 
 //===----------------------------------------------------------------------===//
+// 2.9.4 distribute Construct
+//===----------------------------------------------------------------------===//
+def DistributeOp : OpenMP_Op<"distribute", [RecursiveMemoryEffects]> {
+  let summary = "distribute construct";
+  let description = [{
+    TODO Replace placeholder with upstream definition
+  }];
+
+  let arguments = (ins);
+
+  let regions = (region AnyRegion:$region);
+
+  let assemblyFormat = [{
+    $region attr-dict
+  }];
+
+  let hasVerifier = 0;
+}
+
+//===----------------------------------------------------------------------===//
 // 2.10.1 task Construct
 //===----------------------------------------------------------------------===//
 
@@ -1439,9 +1459,21 @@
 
     The optional $thread_limit specifies the limit on the number of threads
 
-    The optional $nowait elliminates the implicit barrier so the parent task can make progress
+    The optional $trip_count indicates the total number of loop iterations, only if this
+    target region represents a single teams+distribute+parallel worksharing loop.
+
+    The optional $nowait eliminates the implicit barrier so the parent task can make progress
     even if the target task is not yet completed.
 
+    The optional $num_teams_lower, $num_teams_upper and $teams_thread_limit
+    arguments represent the corresponding arguments of a directly nested TeamsOp. They
+    can be only set in this operation when representing combined or composite constructs
+    that include TARGET and TEAMS, so that they can be evaluated in the host device.
+
+    The optional $num_threads argument represents the corresponding argument of a nested
+    ParallelOp, which is only allowed if this target region contains a single (possibly
+    multi-level) nest of OpenMP operations including a ParallelOp.
+
     TODO:  is_device_ptr, depend, defaultmap, in_reduction
 
   }];
@@ -1449,8 +1481,13 @@
   let arguments = (ins Optional<I1>:$if_expr,
                        Optional<AnyInteger>:$device,
                        Optional<AnyInteger>:$thread_limit,
+                       Optional<AnyInteger>:$trip_count,
                        UnitAttr:$nowait,
-                       Variadic<AnyType>:$map_operands);
+                       Variadic<AnyType>:$map_operands,
+                       Optional<AnyInteger>:$num_teams_lower,
+                       Optional<AnyInteger>:$num_teams_upper,
+                       Optional<AnyInteger>:$teams_thread_limit,
+                       Optional<AnyInteger>:$num_threads);
 
   let regions = (region AnyRegion:$region);
 
@@ -1458,12 +1495,32 @@
     oilist( `if` `(` $if_expr `)`
     | `device` `(` $device `:` type($device) `)`
     | `thread_limit` `(` $thread_limit `:` type($thread_limit) `)`
+    | `trip_count` `(` $trip_count `:` type($trip_count) `)`
     | `nowait` $nowait
     | `map_entries` `(` custom<MapEntries>($map_operands, type($map_operands)) `)`
+    | `num_teams` `(` ( $num_teams_lower^ `:` type($num_teams_lower) )? `to`
+                        $num_teams_upper `:` type($num_teams_upper) `)`
+    | `teams_thread_limit` `(` $teams_thread_limit `:` type($teams_thread_limit) `)`
+    | `num_threads` `(` $num_threads `:` type($num_threads) `)`
     ) $region attr-dict
   }];
 
   let hasVerifier = 1;
+
+  let extraClassDeclaration = [{
+    /// Returns the innermost OpenMP dialect operation nested inside of this
+    /// operation's region. For an operation to be detected as captured, it must
+    /// be inside a (possibly multi-level) nest of OpenMP dialect operation's
+    /// regions where none of these levels contain other operations considered
+    /// not-allowed for these purposes (i.e. only terminator operations are
+    /// allowed from the OpenMP dialect, and other dialect's operations are
+    /// allowed as long as they don't have a memory write effect).
+    Operation *getInnermostCapturedOmpOp();
+
+    /// Tells whether this target region represents a single worksharing loop
+    /// wrapped by omp.teams omp.distribute and omp.parallel constructs.
+    bool isTargetSPMDLoop();
+  }];
 }
 
 
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/mlir/include/mlir/Interfaces/CSEInterfaces.h llvm-project/mlir/include/mlir/Interfaces/CSEInterfaces.h
--- llvm-project.upstream/mlir/include/mlir/Interfaces/CSEInterfaces.h	1969-12-31 19:00:00.000000000 -0500
+++ llvm-project/mlir/include/mlir/Interfaces/CSEInterfaces.h	2023-12-18 11:22:51.578721552 -0500
@@ -0,0 +1,32 @@
+//===- CSEInterfaces.h ------------------------------------------*- C++ -*-===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+#ifndef MLIR_INTERFACES_CSEINTERFACES_H_
+#define MLIR_INTERFACES_CSEINTERFACES_H_
+
+#include "mlir/IR/DialectInterface.h"
+
+namespace mlir {
+class Operation;
+
+/// Define an interface to allow for dialects to control specific aspects of
+/// common subexpression elimination behavior for operations they define.
+class DialectCSEInterface : public DialectInterface::Base<DialectCSEInterface> {
+public:
+  DialectCSEInterface(Dialect *dialect) : Base(dialect) {}
+
+  /// Registered hook to check if an operation that is *not* isolated from
+  /// above, should allow common subexpressions to be extracted out of its
+  /// regions.
+  virtual bool subexpressionExtractionAllowed(Operation *op) const {
+    return true;
+  }
+};
+
+} // namespace mlir
+
+#endif // MLIR_INTERFACES_CSEINTERFACES_H_
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/mlir/lib/Conversion/OpenMPToLLVM/OpenMPToLLVM.cpp llvm-project/mlir/lib/Conversion/OpenMPToLLVM/OpenMPToLLVM.cpp
--- llvm-project.upstream/mlir/lib/Conversion/OpenMPToLLVM/OpenMPToLLVM.cpp	2023-10-24 10:07:09.244429619 -0400
+++ llvm-project/mlir/lib/Conversion/OpenMPToLLVM/OpenMPToLLVM.cpp	2023-12-18 11:22:51.582721537 -0500
@@ -228,10 +228,11 @@
     ConversionTarget &target, LLVMTypeConverter &typeConverter) {
   target.addDynamicallyLegalOp<
       mlir::omp::AtomicUpdateOp, mlir::omp::CriticalOp, mlir::omp::TargetOp,
-      mlir::omp::DataOp, mlir::omp::OrderedRegionOp, mlir::omp::ParallelOp,
-      mlir::omp::WsLoopOp, mlir::omp::SimdLoopOp, mlir::omp::MasterOp,
-      mlir::omp::SectionOp, mlir::omp::SectionsOp, mlir::omp::SingleOp,
-      mlir::omp::TaskGroupOp, mlir::omp::TaskOp>([&](Operation *op) {
+      mlir::omp::TeamsOp, mlir::omp::DistributeOp, mlir::omp::DataOp,
+      mlir::omp::OrderedRegionOp, mlir::omp::ParallelOp, mlir::omp::WsLoopOp,
+      mlir::omp::SimdLoopOp, mlir::omp::MasterOp, mlir::omp::SectionOp,
+      mlir::omp::SectionsOp, mlir::omp::SingleOp, mlir::omp::TaskGroupOp,
+      mlir::omp::TaskOp>([&](Operation *op) {
     return typeConverter.isLegal(&op->getRegion(0)) &&
            typeConverter.isLegal(op->getOperandTypes()) &&
            typeConverter.isLegal(op->getResultTypes());
@@ -275,6 +276,7 @@
       RegionOpConversion<omp::SimdLoopOp>, RegionOpConversion<omp::SingleOp>,
       RegionOpConversion<omp::TaskGroupOp>, RegionOpConversion<omp::TaskOp>,
       RegionOpConversion<omp::DataOp>, RegionOpConversion<omp::TargetOp>,
+      RegionOpConversion<omp::TeamsOp>, RegionOpConversion<omp::DistributeOp>,
       RegionLessOpWithVarOperandsConversion<omp::AtomicWriteOp>,
       RegionOpWithVarOperandsConversion<omp::AtomicUpdateOp>,
       RegionLessOpWithVarOperandsConversion<omp::FlushOp>,
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/mlir/lib/Dialect/OpenMP/IR/OpenMPDialect.cpp llvm-project/mlir/lib/Dialect/OpenMP/IR/OpenMPDialect.cpp
--- llvm-project.upstream/mlir/lib/Dialect/OpenMP/IR/OpenMPDialect.cpp	2023-12-18 11:20:50.567178272 -0500
+++ llvm-project/mlir/lib/Dialect/OpenMP/IR/OpenMPDialect.cpp	2023-12-18 12:24:58.281789284 -0500
@@ -18,6 +18,7 @@
 #include "mlir/IR/DialectImplementation.h"
 #include "mlir/IR/OpImplementation.h"
 #include "mlir/IR/OperationSupport.h"
+#include "mlir/Interfaces/CSEInterfaces.h"
 #include "mlir/Interfaces/FoldInterfaces.h"
 
 #include "llvm/ADT/BitVector.h"
@@ -53,6 +54,15 @@
   Type getElementType(Type pointer) const { return Type(); }
 };
 
+struct OpenMPDialectCSEInterface : public DialectCSEInterface {
+  using DialectCSEInterface::DialectCSEInterface;
+
+  bool subexpressionExtractionAllowed(Operation *op) const final {
+    // Avoid extracting common subexpressions across op boundaries
+    return !isa<TargetOp>(op);
+  }
+};
+
 struct OpenMPDialectFoldInterface : public DialectFoldInterface {
   using DialectFoldInterface::DialectFoldInterface;
 
@@ -77,6 +87,7 @@
 #include "mlir/Dialect/OpenMP/OpenMPOpsTypes.cpp.inc"
       >();
 
+  addInterface<OpenMPDialectCSEInterface>();
   addInterface<OpenMPDialectFoldInterface>();
   MemRefType::attachInterface<MemRefPointerLikeModel>(*getContext());
   LLVM::LLVMPointerType::attachInterface<LLVMPointerPointerLikeModel>(
@@ -979,14 +990,157 @@
   return verifyMapClause(*this, getMapOperands());
 }
 
+//===----------------------------------------------------------------------===//
+// TargetOp
+//===----------------------------------------------------------------------===//
+
+static LogicalResult verifyNumTeamsClause(Operation *op, Value lb, Value ub) {
+  if (lb) {
+    if (!ub)
+      return op->emitError("expected num_teams upper bound to be defined if "
+                           "the lower bound is defined");
+    if (lb.getType() != ub.getType())
+      return op->emitError(
+          "expected num_teams upper bound and lower bound to be the same type");
+  }
+  return success();
+}
+
+template <typename OpTy>
+static OpTy getSingleNestedOpOfType(Region &region) {
+  auto ops = region.getOps<OpTy>();
+  return std::distance(ops.begin(), ops.end()) != 1 ? OpTy() : *ops.begin();
+}
 LogicalResult UpdateDataOp::verify() {
   return verifyMapClause(*this, getMotionOperands());
 }
 
+/// Only allow OpenMP terminators and non-OpenMP ops that have known memory
+/// effects, but don't include a memory write effect.
+static bool siblingAllowedInCapture(Operation *op) {
+  if (!op)
+    return false;
+
+  bool isOmpDialect =
+      op->getContext()->getLoadedDialect<omp::OpenMPDialect>() ==
+      op->getDialect();
+
+  if (isOmpDialect)
+    return op->hasTrait<OpTrait::IsTerminator>();
+
+  if (auto memOp = dyn_cast<MemoryEffectOpInterface>(op)) {
+    SmallVector<SideEffects::EffectInstance<MemoryEffects::Effect>, 4> effects;
+    memOp.getEffects(effects);
+    return !llvm::any_of(effects, [&](MemoryEffects::EffectInstance &effect) {
+      // FIXME Ideally we'd just check for a memory write effect. However, this
+      // would break due to HLFIR operations that in reality have no side
+      // effects but are marked as having a memory write effect on a debug
+      // resource to avoid being deleted by DCE passes.
+      return isa<MemoryEffects::Write>(effect.getEffect()) &&
+             isa<SideEffects::AutomaticAllocationScopeResource>(
+                 effect.getResource());
+    });
+  }
+  return true;
+}
+
 LogicalResult TargetOp::verify() {
+  auto teamsOps = getOps<TeamsOp>();
+  if (std::distance(teamsOps.begin(), teamsOps.end()) > 1)
+    return emitError("target containing multiple teams constructs");
+
+  if (!isTargetSPMDLoop()) {
+    if (getTripCount())
+      return emitError("trip_count set on non-SPMD target region");
+
+    if (getNumThreads() && !getSingleNestedOpOfType<ParallelOp>(getRegion()))
+      return emitError("num_threads set on non-SPMD or loop target region");
+  }
+
+  if (teamsOps.empty()) {
+    if (getNumTeamsLower() || getNumTeamsUpper() || getTeamsThreadLimit())
+      return emitError(
+          "num_teams and teams_thread_limit arguments only allowed if there is "
+          "an omp.teams child operation");
+  } else {
+    if (failed(verifyNumTeamsClause(*this, getNumTeamsLower(),
+                                    getNumTeamsUpper())))
+      return failure();
+  }
+
   return verifyMapClause(*this, getMapOperands());
 }
 
+Operation *TargetOp::getInnermostCapturedOmpOp() {
+  Dialect *ompDialect = (*this)->getDialect();
+  Operation *capturedOp = nullptr;
+  Region *capturedParentRegion = nullptr;
+
+  walk<WalkOrder::PostOrder>([&](Operation *op) {
+    if (op == *this)
+      return;
+
+    bool isOmpDialect = op->getDialect() == ompDialect;
+    bool hasRegions = op->getNumRegions() > 0;
+
+    if (capturedOp) {
+      bool isImmediateParent = false;
+      for (Region &region : op->getRegions()) {
+        if (&region == capturedParentRegion) {
+          isImmediateParent = true;
+          capturedParentRegion = op->getParentRegion();
+          break;
+        }
+      }
+
+      // Make sure the captured op is part of a (possibly multi-level) nest of
+      // OpenMP-only operations containing no unsupported siblings at any level.
+      if ((hasRegions && isOmpDialect != isImmediateParent) ||
+          (!isImmediateParent && !siblingAllowedInCapture(op))) {
+        capturedOp = nullptr;
+        capturedParentRegion = nullptr;
+      }
+    } else {
+      //  The first OpenMP dialect op containing a region found while visiting
+      //  in post-order should be the innermost captured OpenMP operation.
+      if (isOmpDialect && hasRegions) {
+        capturedOp = op;
+        capturedParentRegion = op->getParentRegion();
+
+        // Don't capture this op if it has a not-allowed sibling.
+        for (Operation &sibling : op->getParentRegion()->getOps()) {
+          if (&sibling != op && !siblingAllowedInCapture(&sibling)) {
+            capturedOp = nullptr;
+            capturedParentRegion = nullptr;
+          }
+        }
+      }
+    }
+  });
+
+  return capturedOp;
+}
+
+bool TargetOp::isTargetSPMDLoop() {
+  Operation *capturedOp = getInnermostCapturedOmpOp();
+  if (!isa_and_present<WsLoopOp, SimdLoopOp>(capturedOp))
+    return false;
+
+  Operation *parallelOp = capturedOp->getParentOp();
+  if (!isa_and_present<ParallelOp>(parallelOp))
+    return false;
+
+  Operation *distributeOp = parallelOp->getParentOp();
+  if (!isa_and_present<DistributeOp>(distributeOp))
+    return false;
+
+  Operation *teamsOp = distributeOp->getParentOp();
+  if (!isa_and_present<TeamsOp>(teamsOp))
+    return false;
+
+  return teamsOp->getParentOp() == (*this);
+}
+
 //===----------------------------------------------------------------------===//
 // ParallelOp
 //===----------------------------------------------------------------------===//
@@ -1005,6 +1159,18 @@
   if (getAllocateVars().size() != getAllocatorsVars().size())
     return emitError(
         "expected equal sizes for allocate and allocator variables");
+
+  auto offloadModOp =
+      llvm::cast<OffloadModuleInterface>(*(*this)->getParentOfType<ModuleOp>());
+  if (!offloadModOp.getIsTargetDevice()) {
+    auto targetOp = (*this)->getParentOfType<omp::TargetOp>();
+    if (getNumThreadsVar() && targetOp &&
+        (targetOp.isTargetSPMDLoop() ||
+         getSingleNestedOpOfType<ParallelOp>(targetOp.getRegion()) == *this))
+      return emitError("num_threads argument expected to be attached to parent "
+                       "omp.target operation instead");
+  }
+
   return verifyReductionVarList(*this, getReductions(), getReductionVars());
 }
 
@@ -1023,23 +1189,23 @@
   // Check parent region
   // TODO If nested inside of a target region, also check that it does not
   // contain any statements, declarations or directives other than this
-  // omp.teams construct. The issue is how to support the initialization of
-  // this operation's own arguments (allow SSA values across omp.target?).
-  Operation *op = getOperation();
-  if (!isa<TargetOp>(op->getParentOp()) &&
-      !opInGlobalImplicitParallelRegion(op))
+  // omp.teams construct.
+  auto targetOp = dyn_cast_if_present<TargetOp>((*this)->getParentOp());
+
+  if (!targetOp && !opInGlobalImplicitParallelRegion(*this))
     return emitError("expected to be nested inside of omp.target or not nested "
                      "in any OpenMP dialect operations");
 
-  // Check for num_teams clause restrictions
-  if (auto numTeamsLowerBound = getNumTeamsLower()) {
-    auto numTeamsUpperBound = getNumTeamsUpper();
-    if (!numTeamsUpperBound)
-      return emitError("expected num_teams upper bound to be defined if the "
-                       "lower bound is defined");
-    if (numTeamsLowerBound.getType() != numTeamsUpperBound.getType())
-      return emitError(
-          "expected num_teams upper bound and lower bound to be the same type");
+  auto offloadModOp =
+      llvm::cast<OffloadModuleInterface>(*(*this)->getParentOfType<ModuleOp>());
+  if (targetOp && !offloadModOp.getIsTargetDevice()) {
+    if (getNumTeamsLower() || getNumTeamsUpper() || getThreadLimit())
+      return emitError("num_teams and thread_limit arguments expected to be "
+                       "attached to parent omp.target operation");
+  } else {
+    if (failed(verifyNumTeamsClause(*this, getNumTeamsLower(),
+                                    getNumTeamsUpper())))
+      return failure();
   }
 
   // Check for allocate clause restrictions
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp llvm-project/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp
--- llvm-project.upstream/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp	2023-12-18 11:20:50.591178181 -0500
+++ llvm-project/mlir/lib/Target/LLVMIR/Dialect/OpenMP/OpenMPToLLVMIRTranslation.cpp	2023-12-18 12:24:58.285789269 -0500
@@ -694,9 +694,11 @@
   if (Value ifExprVar = op.getIfExpr())
     ifExpr = moduleTranslation.lookupValue(ifExprVar);
 
+  llvm::OpenMPIRBuilder *ompBuilder = moduleTranslation.getOpenMPBuilder();
   llvm::OpenMPIRBuilder::LocationDescription ompLoc(builder);
-  builder.restoreIP(moduleTranslation.getOpenMPBuilder()->createTeams(
+  builder.restoreIP(ompBuilder->createTeams(
       ompLoc, bodyCB, numTeamsLower, numTeamsUpper, threadLimit, ifExpr));
+
   return bodyGenStatus;
 }
 
@@ -833,6 +835,50 @@
   }
 }
 
+/// Populate a set of previously created llvm.alloca instructions that are only
+/// used inside of the given region but defined outside of it. Allocations of
+/// non-primitive types are skipped by this function.
+static void getSinkableAllocas(LLVM::ModuleTranslation &moduleTranslation,
+                               Region &region,
+                               SetVector<llvm::AllocaInst *> &allocasToSink) {
+  Operation *op = region.getParentOp();
+
+  for (auto storeOp : region.getOps<LLVM::StoreOp>()) {
+    Value storeAddr = storeOp.getAddr();
+    Operation *addrOp = storeAddr.getDefiningOp();
+
+    // The destination address is already defined in this region or it is not an
+    // llvm.alloca operation, so skip it.
+    if (!isa_and_present<LLVM::AllocaOp>(addrOp) || op->isAncestor(addrOp))
+      continue;
+
+    // Get LLVM value to which the address is mapped. It has to be mapped to the
+    // allocation instruction of a scalar type to be marked as sinkable by this
+    // function.
+    llvm::Value *llvmAddr = moduleTranslation.lookupValue(storeAddr);
+    if (!isa_and_present<llvm::AllocaInst>(llvmAddr))
+      continue;
+
+    auto *llvmAlloca = cast<llvm::AllocaInst>(llvmAddr);
+    if (llvmAlloca->getAllocatedType()->getPrimitiveSizeInBits() == 0)
+      continue;
+
+    // Check that the address is only used inside of the region.
+    bool addressUsedOnlyInternally = true;
+    for (auto &addrUse : storeAddr.getUses()) {
+      if (!op->isAncestor(addrUse.getOwner())) {
+        addressUsedOnlyInternally = false;
+        break;
+      }
+    }
+
+    if (!addressUsedOnlyInternally)
+      continue;
+
+    allocasToSink.insert(llvmAlloca);
+  }
+}
+
 /// Converts an OpenMP workshare loop into LLVM IR using OpenMPIRBuilder.
 static LogicalResult
 convertOmpWsLoop(Operation &opInst, llvm::IRBuilderBase &builder,
@@ -889,6 +935,9 @@
   // Set up the source location value for OpenMP runtime.
   llvm::OpenMPIRBuilder::LocationDescription ompLoc(builder);
 
+  SetVector<llvm::AllocaInst *> allocasToSink;
+  getSinkableAllocas(moduleTranslation, loop.getRegion(), allocasToSink);
+
   // Generator of the canonical loop body.
   // TODO: support error propagation in OpenMPIRBuilder and use it instead of
   // relying on captured variables.
@@ -908,10 +957,21 @@
     if (loopInfos.size() != loop.getNumLoops() - 1)
       return;
 
-    // Convert the body of the loop.
+    // Convert the body of the loop, adding lifetime markers to allocations that
+    // can be sunk into the new block.
     builder.restoreIP(ip);
-    convertOmpOpRegions(loop.getRegion(), "omp.wsloop.region", builder,
-                        moduleTranslation, bodyGenStatus);
+    for (auto *alloca : allocasToSink) {
+      unsigned size = alloca->getAllocatedType()->getPrimitiveSizeInBits() / 8;
+      builder.CreateLifetimeStart(alloca, builder.getInt64(size));
+    }
+    llvm::BasicBlock *cont =
+        convertOmpOpRegions(loop.getRegion(), "omp.wsloop.region", builder,
+                            moduleTranslation, bodyGenStatus);
+    builder.SetInsertPoint(cont, cont->begin());
+    for (auto *alloca : allocasToSink) {
+      unsigned size = alloca->getAllocatedType()->getPrimitiveSizeInBits() / 8;
+      builder.CreateLifetimeEnd(alloca, builder.getInt64(size));
+    }
   };
 
   // Delegate actual loop construction to the OpenMP IRBuilder.
@@ -956,12 +1016,24 @@
   std::optional<omp::ScheduleModifier> scheduleModifier =
       loop.getScheduleModifier();
   bool isSimd = loop.getSimdModifier();
-
-  ompBuilder->applyWorkshareLoop(
-      ompLoc.DL, loopInfo, allocaIP, !loop.getNowait(),
-      convertToScheduleKind(schedule), chunk, isSimd,
-      scheduleModifier == omp::ScheduleModifier::monotonic,
-      scheduleModifier == omp::ScheduleModifier::nonmonotonic, isOrdered);
+  // TODO: Handle distribute loop without parallel clause
+  bool distributeParallelCodeGen = opInst.getParentOfType<omp::DistributeOp>();
+  if (distributeParallelCodeGen) {
+    ompBuilder->applyWorkshareLoop(
+        ompLoc.DL, loopInfo, allocaIP, !loop.getNowait(),
+        convertToScheduleKind(schedule), chunk, isSimd,
+        scheduleModifier == omp::ScheduleModifier::monotonic,
+        scheduleModifier == omp::ScheduleModifier::nonmonotonic, isOrdered,
+        llvm::omp::WorksharingLoopType::DistributeForStaticLoop);
+  }
+  else {
+    ompBuilder->applyWorkshareLoop(
+        ompLoc.DL, loopInfo, allocaIP, !loop.getNowait(),
+        convertToScheduleKind(schedule), chunk, isSimd,
+        scheduleModifier == omp::ScheduleModifier::monotonic,
+        scheduleModifier == omp::ScheduleModifier::nonmonotonic, isOrdered,
+        llvm::omp::WorksharingLoopType::ForStaticLoop);
+  }
 
   // Continue building IR after the loop. Note that the LoopInfo returned by
   // `collapseLoops` points inside the outermost loop and is intended for
@@ -1130,6 +1202,9 @@
 
   llvm::OpenMPIRBuilder::LocationDescription ompLoc(builder);
 
+  SetVector<llvm::AllocaInst *> allocasToSink;
+  getSinkableAllocas(moduleTranslation, loop.getRegion(), allocasToSink);
+
   // Generator of the canonical loop body.
   // TODO: support error propagation in OpenMPIRBuilder and use it instead of
   // relying on captured variables.
@@ -1149,10 +1224,21 @@
     if (loopInfos.size() != loop.getNumLoops() - 1)
       return;
 
-    // Convert the body of the loop.
+    // Convert the body of the loop, adding lifetime markers to allocations that
+    // can be sunk into the new block.
     builder.restoreIP(ip);
-    convertOmpOpRegions(loop.getRegion(), "omp.simdloop.region", builder,
-                        moduleTranslation, bodyGenStatus);
+    for (auto *alloca : allocasToSink) {
+      unsigned size = alloca->getAllocatedType()->getPrimitiveSizeInBits() / 8;
+      builder.CreateLifetimeStart(alloca, builder.getInt64(size));
+    }
+    llvm::BasicBlock *cont =
+        convertOmpOpRegions(loop.getRegion(), "omp.simdloop.region", builder,
+                            moduleTranslation, bodyGenStatus);
+    builder.SetInsertPoint(cont, cont->begin());
+    for (auto *alloca : allocasToSink) {
+      unsigned size = alloca->getAllocatedType()->getPrimitiveSizeInBits() / 8;
+      builder.CreateLifetimeEnd(alloca, builder.getInt64(size));
+    }
   };
 
   // Delegate actual loop construction to the OpenMP IRBuilder.
@@ -2025,6 +2111,37 @@
   return bodyGenStatus;
 }
 
+static LogicalResult
+convertOmpDistribute(Operation &opInst, llvm::IRBuilderBase &builder,
+                     LLVM::ModuleTranslation &moduleTranslation) {
+
+  using InsertPointTy = llvm::OpenMPIRBuilder::InsertPointTy;
+  // TODO: support error propagation in OpenMPIRBuilder and use it instead of
+  // relying on captured variables.
+  LogicalResult bodyGenStatus = success();
+
+  auto bodyGenCB = [&](InsertPointTy allocaIP, InsertPointTy codeGenIP) {
+    // Save the alloca insertion point on ModuleTranslation stack for use in
+    // nested regions.
+    LLVM::ModuleTranslation::SaveStack<OpenMPAllocaStackFrame> frame(
+        moduleTranslation, allocaIP);
+
+    // DistributeOp has only one region associated with it.
+    builder.restoreIP(codeGenIP);
+    convertOmpOpRegions(opInst.getRegion(0), "omp.distribute.region", builder,
+                        moduleTranslation, bodyGenStatus);
+  };
+
+  llvm::OpenMPIRBuilder::InsertPointTy allocaIP =
+      findAllocaInsertPoint(builder, moduleTranslation);
+  llvm::OpenMPIRBuilder::LocationDescription ompLoc(builder);
+
+  builder.restoreIP(moduleTranslation.getOpenMPBuilder()->createDistribute(
+      ompLoc, allocaIP, bodyGenCB));
+
+  return bodyGenStatus;
+}
+
 /// Lowers the FlagsAttr which is applied to the module on the device
 /// pass when offloading, this attribute contains OpenMP RTL globals that can
 /// be passed as flags to the frontend, otherwise they are set to default
@@ -2093,11 +2210,6 @@
     return false;
   }
 
-  if (targetOp.getThreadLimit()) {
-    opInst.emitError("Thread limit clause not yet supported");
-    return false;
-  }
-
   if (targetOp.getNowait()) {
     opInst.emitError("Nowait clause not yet supported");
     return false;
@@ -2322,6 +2434,145 @@
   }
 }
 
+template <typename OpTy>
+static OpTy castOrGetParentOfType(Operation *op, bool immediateParent = false) {
+  if (!op)
+    return OpTy();
+
+  if (OpTy casted = dyn_cast<OpTy>(op))
+    return casted;
+
+  if (immediateParent)
+    return dyn_cast_if_present<OpTy>(op->getParentOp());
+
+  return op->getParentOfType<OpTy>();
+}
+
+/// Populate default `MinTeams`, `MaxTeams` and `MaxThreads` to their default
+/// values as stated by the corresponding clauses, if constant.
+///
+/// These default values must be set before the creation of the outlined LLVM
+/// function for the target region, so that they can be used to initialize the
+/// corresponding global `ConfigurationEnvironmentTy` structure.
+static void initTargetDefaultBounds(
+    omp::TargetOp targetOp,
+    llvm::OpenMPIRBuilder::TargetKernelDefaultBounds &bounds,
+    bool isTargetDevice) {
+  // TODO Handle constant IF clauses
+  Operation *innermostCapturedOmpOp = targetOp.getInnermostCapturedOmpOp();
+
+  // Handle clauses impacting the number of teams.
+  int32_t minTeamsVal = 1, maxTeamsVal = -1;
+  if (auto teamsOp =
+          castOrGetParentOfType<omp::TeamsOp>(innermostCapturedOmpOp)) {
+    // TODO Use teamsOp.getNumTeamsLower() to initialize `minTeamsVal`. For now,
+    // just match clang and set min and max to the same value.
+    Value numTeamsClause = isTargetDevice ? teamsOp.getNumTeamsUpper()
+                                          : targetOp.getNumTeamsUpper();
+    if (numTeamsClause) {
+      if (auto constOp = dyn_cast_if_present<LLVM::ConstantOp>(
+              numTeamsClause.getDefiningOp())) {
+        if (auto constAttr = constOp.getValue().dyn_cast<IntegerAttr>())
+          minTeamsVal = maxTeamsVal = constAttr.getInt();
+      }
+    } else {
+      minTeamsVal = maxTeamsVal = 0;
+    }
+  } else if (castOrGetParentOfType<omp::ParallelOp>(innermostCapturedOmpOp,
+                                                    /*immediateParent=*/true) ||
+             castOrGetParentOfType<omp::SimdLoopOp>(innermostCapturedOmpOp,
+                                                    /*immediateParent=*/true)) {
+    minTeamsVal = maxTeamsVal = 1;
+  } else {
+    minTeamsVal = maxTeamsVal = -1;
+  }
+
+  // Handle clauses impacting the number of threads.
+  int32_t targetThreadLimitVal = -1;
+  int32_t teamsThreadLimitVal = -1;
+  int32_t maxThreadsVal = -1;
+
+  auto setMaxValueFromClause = [](Value clauseValue, int32_t &result) {
+    if (clauseValue) {
+      if (auto constOp = dyn_cast_if_present<LLVM::ConstantOp>(
+              clauseValue.getDefiningOp())) {
+        if (auto constAttr = constOp.getValue().dyn_cast<IntegerAttr>())
+          result = constAttr.getInt();
+      }
+      // Found an applicable clause, so it's not undefined. Mark as unknown
+      // because it's not constant.
+      if (result < 0)
+        result = 0;
+    }
+  };
+
+  // Extract THREAD_LIMIT clause from TARGET and TEAMS directives.
+  setMaxValueFromClause(targetOp.getThreadLimit(), targetThreadLimitVal);
+
+  if (auto teamsOp =
+          castOrGetParentOfType<omp::TeamsOp>(innermostCapturedOmpOp)) {
+    Value threadLimitClause = isTargetDevice ? teamsOp.getThreadLimit()
+                                             : targetOp.getTeamsThreadLimit();
+    setMaxValueFromClause(threadLimitClause, teamsThreadLimitVal);
+  }
+
+  // Extract MAX_THREADS clause from PARALLEL or set to 1 if it's SIMD.
+  if (innermostCapturedOmpOp) {
+    if (auto parallelOp =
+            castOrGetParentOfType<omp::ParallelOp>(innermostCapturedOmpOp,
+                                                   /*immediateParent=*/true)) {
+      Value numThreadsClause = isTargetDevice ? parallelOp.getNumThreadsVar()
+                                              : targetOp.getNumThreads();
+      setMaxValueFromClause(numThreadsClause, maxThreadsVal);
+    } else if (isa<omp::SimdLoopOp>(innermostCapturedOmpOp)) {
+      maxThreadsVal = 1;
+    }
+  }
+
+  // For max values, < 0 means unset, == 0 means set but unknown. Select the
+  // minimum value between MAX_THREADS and THREAD_LIMIT clauses that were set.
+  int32_t combinedMaxThreadsVal = targetThreadLimitVal;
+  if (combinedMaxThreadsVal < 0 ||
+      (teamsThreadLimitVal >= 0 && teamsThreadLimitVal < combinedMaxThreadsVal))
+    combinedMaxThreadsVal = teamsThreadLimitVal;
+
+  if (combinedMaxThreadsVal < 0 ||
+      (maxThreadsVal >= 0 && maxThreadsVal < combinedMaxThreadsVal))
+    combinedMaxThreadsVal = maxThreadsVal;
+
+  // Update kernel bounds structure for the `OpenMPIRBuilder` to use.
+  bounds.MinTeams = minTeamsVal;
+  bounds.MaxTeams = maxTeamsVal;
+  bounds.MinThreads = 1;
+  bounds.MaxThreads = combinedMaxThreadsVal;
+}
+
+/// Gather LLVM runtime values for all clauses evaluated in the host that are
+/// passed to the kernel invocation.
+///
+/// This function must be called only when compiling for the host. Also, it will
+/// only provide correct results if it's called after the body of \c targetOp
+/// has been fully generated.
+static void initTargetRuntimeBounds(
+    LLVM::ModuleTranslation &moduleTranslation, omp::TargetOp targetOp,
+    llvm::OpenMPIRBuilder::TargetKernelRuntimeBounds &bounds) {
+  // TODO Handle IF clauses.
+  if (Value numTeamsLower = targetOp.getNumTeamsLower())
+    bounds.MinTeams = moduleTranslation.lookupValue(numTeamsLower);
+
+  if (Value numTeamsUpper = targetOp.getNumTeamsUpper())
+    bounds.MaxTeams = moduleTranslation.lookupValue(numTeamsUpper);
+
+  if (Value teamsThreadLimit = targetOp.getTeamsThreadLimit())
+    bounds.TeamsThreadLimit = moduleTranslation.lookupValue(teamsThreadLimit);
+
+  if (Value numThreads = targetOp.getNumThreads())
+    bounds.MaxThreads = moduleTranslation.lookupValue(numThreads);
+
+  if (Value tripCount = targetOp.getTripCount())
+    bounds.LoopTripCount = moduleTranslation.lookupValue(tripCount);
+}
+
 static LogicalResult
 convertOmpTarget(Operation &opInst, llvm::IRBuilderBase &builder,
                  LLVM::ModuleTranslation &moduleTranslation) {
@@ -2329,11 +2580,14 @@
   if (!targetOpSupported(opInst))
     return failure();
 
+  llvm::OpenMPIRBuilder *ompBuilder = moduleTranslation.getOpenMPBuilder();
+  bool isTargetDevice = ompBuilder->Config.isTargetDevice();
   auto targetOp = cast<omp::TargetOp>(opInst);
   auto &targetRegion = targetOp.getRegion();
   DataLayout dl = DataLayout(opInst.getParentOfType<ModuleOp>());
   SmallVector<Value> mapOperands = targetOp.getMapOperands();
 
+  llvm::OpenMPIRBuilder::TargetKernelRuntimeBounds runtimeBounds;
   LogicalResult bodyGenStatus = success();
   using InsertPointTy = llvm::OpenMPIRBuilder::InsertPointTy;
   auto bodyCB = [&](InsertPointTy allocaIP,
@@ -2352,6 +2606,10 @@
     llvm::BasicBlock *exitBlock = convertOmpOpRegions(
         targetRegion, "omp.target", builder, moduleTranslation, bodyGenStatus);
     builder.SetInsertPoint(exitBlock);
+
+    if (!isTargetDevice)
+      initTargetRuntimeBounds(moduleTranslation, targetOp, runtimeBounds);
+
     return builder.saveIP();
   };
 
@@ -2370,9 +2628,6 @@
   if (!getTargetEntryUniqueInfo(entryInfo, targetOp, parentName))
     return failure();
 
-  int32_t defaultValTeams = -1;
-  int32_t defaultValThreads = 0;
-
   llvm::OpenMPIRBuilder::InsertPointTy allocaIP =
       findAllocaInsertPoint(builder, moduleTranslation);
 
@@ -2391,7 +2646,7 @@
   // kernel arg structure. It primarily becomes relevant in cases like
   // bycopy, or byref range'd arrays. In the default case, we simply
   // pass thee pointer byref as both basePointer and pointer.
-  if (!moduleTranslation.getOpenMPBuilder()->Config.isTargetDevice())
+  if (!isTargetDevice)
     createAlteredByCaptureMap(mapData, moduleTranslation, builder);
 
   llvm::OpenMPIRBuilder::MapInfosTy combinedInfos;
@@ -2406,14 +2661,12 @@
   auto argAccessorCB = [&](llvm::Argument &arg, llvm::Value *input,
                            llvm::Value *&retVal, InsertPointTy allocaIP,
                            InsertPointTy codeGenIP) {
-    llvm::OpenMPIRBuilder *ompBuilder = moduleTranslation.getOpenMPBuilder();
-
     // We just return the unaltered argument for the host function
     // for now, some alterations may be required in the future to
     // keep host fallback functions working identically to the device
     // version (e.g. pass ByCopy values should be treated as such on
     // host and device, currently not always the case)
-    if (!ompBuilder->Config.isTargetDevice()) {
+    if (!isTargetDevice) {
       retVal = cast<llvm::Value>(&arg);
       return codeGenIP;
     }
@@ -2430,13 +2683,21 @@
       kernelInput.push_back(mapData.OriginalValue[i]);
   }
 
-  builder.restoreIP(moduleTranslation.getOpenMPBuilder()->createTarget(
-      ompLoc, allocaIP, builder.saveIP(), entryInfo, defaultValTeams,
-      defaultValThreads, kernelInput, genMapInfoCB, bodyCB, argAccessorCB));
+  llvm::OpenMPIRBuilder::TargetKernelDefaultBounds defaultBounds;
+  initTargetDefaultBounds(targetOp, defaultBounds, isTargetDevice);
+
+  if (Value targetThreadLimit = targetOp.getThreadLimit())
+    runtimeBounds.TargetThreadLimit =
+        moduleTranslation.lookupValue(targetThreadLimit);
+
+  builder.restoreIP(ompBuilder->createTarget(
+      ompLoc, targetOp.isTargetSPMDLoop(), allocaIP, builder.saveIP(),
+      entryInfo, defaultBounds, runtimeBounds, kernelInput, genMapInfoCB,
+      bodyCB, argAccessorCB));
 
   // Remap access operations to declare target reference pointers for the
   // device, essentially generating extra loadop's as necessary
-  if (moduleTranslation.getOpenMPBuilder()->Config.isTargetDevice())
+  if (isTargetDevice)
     handleDeclareTargetMapVar(mapData, moduleTranslation, builder);
 
   return bodyGenStatus;
@@ -2658,6 +2919,17 @@
             }
             return failure();
           })
+      .Case("omp.target",
+            [&](Attribute attr) {
+              if (auto targetAttr = attr.dyn_cast<omp::TargetAttr>()) {
+                llvm::OpenMPIRBuilderConfig &config =
+                    moduleTranslation.getOpenMPBuilder()->Config;
+                config.TargetCPU = targetAttr.getTargetCpu();
+                config.TargetFeatures = targetAttr.getTargetFeatures();
+                return success();
+              }
+              return failure();
+            })
       .Default([](Attribute) {
         // Fall through for omp attributes that do not require lowering.
         return success();
@@ -2772,6 +3044,9 @@
       .Case([&](omp::TargetOp) {
         return convertOmpTarget(*op, builder, moduleTranslation);
       })
+      .Case([&](omp::DistributeOp) {
+        return convertOmpDistribute(*op, builder, moduleTranslation);
+      })
       .Case<omp::MapInfoOp, omp::DataBoundsOp>([&](auto op) {
         // No-op, should be handled by relevant owning operations e.g.
         // TargetOp, EnterDataOp, ExitDataOp, DataOp etc. and then
diff -Naur -x .git -x test -x unittests -x docs llvm-project.upstream/mlir/lib/Transforms/CSE.cpp llvm-project/mlir/lib/Transforms/CSE.cpp
--- llvm-project.upstream/mlir/lib/Transforms/CSE.cpp	2023-08-21 13:28:50.509369796 -0400
+++ llvm-project/mlir/lib/Transforms/CSE.cpp	2023-12-18 11:22:51.602721461 -0500
@@ -15,6 +15,7 @@
 
 #include "mlir/IR/Dominance.h"
 #include "mlir/IR/PatternMatch.h"
+#include "mlir/Interfaces/CSEInterfaces.h"
 #include "mlir/Interfaces/SideEffectInterfaces.h"
 #include "mlir/Pass/Pass.h"
 #include "mlir/Transforms/Passes.h"
@@ -61,7 +62,8 @@
 class CSEDriver {
 public:
   CSEDriver(RewriterBase &rewriter, DominanceInfo *domInfo)
-      : rewriter(rewriter), domInfo(domInfo) {}
+      : rewriter(rewriter), domInfo(domInfo),
+        interfaces(rewriter.getContext()) {}
 
   /// Simplify all operations within the given op.
   void simplify(Operation *op, bool *changed = nullptr);
@@ -122,6 +124,9 @@
   DominanceInfo *domInfo = nullptr;
   MemEffectsCache memEffectsCache;
 
+  /// CSE interfaces in the present context that can modify CSE behavior.
+  DialectInterfaceCollection<DialectCSEInterface> interfaces;
+
   // Various statistics.
   int64_t numCSE = 0;
   int64_t numDCE = 0;
@@ -289,7 +294,12 @@
       // If this operation is isolated above, we can't process nested regions
       // with the given 'knownValues' map. This would cause the insertion of
       // implicit captures in explicit capture only regions.
-      if (op.mightHaveTrait<OpTrait::IsIsolatedFromAbove>()) {
+      // Also, avoid capturing known values from parent regions if this behavior
+      // is explicitly disabled for the given operation.
+      const DialectCSEInterface *cseInterface = interfaces.getInterfaceFor(&op);
+      if (op.mightHaveTrait<OpTrait::IsIsolatedFromAbove>() ||
+          LLVM_UNLIKELY(cseInterface &&
+                        !cseInterface->subexpressionExtractionAllowed(&op))) {
         ScopedMapTy nestedKnownValues;
         for (auto &region : op.getRegions())
           simplifyRegion(nestedKnownValues, region);
