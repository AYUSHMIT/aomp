--- OMPStream.cpp.orig	2021-12-08 10:46:57.904123238 -0600
+++ OMPStream.cpp	2021-12-08 10:46:57.908123238 -0600
@@ -12,6 +12,20 @@
 #define ALIGNMENT (2*1024*1024) // 2MB
 #endif
 
+#ifdef OMP_TARGET_GPU
+// vectorization inside target region is not possible, so define simd as a macro
+// to define extra clauses such as schedule and grid sizes.
+// Try 4 X number_of_cus or 2 X number_of_cus
+#define NUM_TEAMS 240
+#define NUM_THREADS 1024
+#define CHUNKSZ 1
+//#define simd schedule(nonmonotonic:static,CHUNKSZ) num_teams(NUM_TEAMS) thread_limit(NUM_THREADS)
+#define simd num_teams(NUM_TEAMS) thread_limit(NUM_THREADS)
+#define XSTR(x) STRING_CLAUSE(x)
+#define STRING_CLAUSE(x) #x
+#endif
+static int didprint = 0;
+
 template <class T>
 OMPStream<T>::OMPStream(const int ARRAY_SIZE, int device)
 {
@@ -27,6 +41,14 @@
   T *a = this->a;
   T *b = this->b;
   T *c = this->c;
+  // Print diagnostic one time.
+  if (!didprint) {
+     printf("#pragma omp target teams distribute parallel for %s\n",XSTR(simd));
+     printf("arrays_size:%d nteams:%d teamsz:%d chunksz:%d iters/thread:%d iters/team:%d chunks/thread:%d\n",
+                  array_size, NUM_TEAMS, NUM_THREADS , CHUNKSZ, (array_size/NUM_TEAMS)/NUM_THREADS,
+                  array_size/NUM_TEAMS,  ((array_size/NUM_TEAMS)/NUM_THREADS)/CHUNKSZ);
+     didprint=1;
+  }
   // Set up data region on device
   #pragma omp target enter data map(alloc: a[0:array_size], b[0:array_size], c[0:array_size])
   {}
